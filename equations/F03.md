F03. ðŸ“¡ Information & Entropy Family
Domain: Shannon entropy, coding theory, information measures, compression.
	â€¢	Shannon EntropyH(X) = -Î£áµ¢ p(xáµ¢) logâ‚‚ p(xáµ¢)â†’ Glyph of Uncertainty Measure
	â€¢	Channel CapacityC = B logâ‚‚(1 + S/N)â†’ Glyph of Perfect Signal
	â€¢	Kullback-Leibler DivergenceD_KL(Pâ€–Q) = Î£áµ¢ P(i) log[P(i)/Q(i)]â†’ Glyph of Distribution Distance
	â€¢	Mutual InformationI(X;Y) = H(X) + H(Y) - H(X,Y)â†’ Glyph of Shared Knowled
